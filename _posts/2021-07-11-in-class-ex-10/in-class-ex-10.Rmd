---
title: "In-Class-Ex-10"
description: |
  Text Visualization and Analytics
author:
  - name: Ryan Chan
    url: https://www.linkedin.com/in/ryan-chan-a7021b5/
date: 07-11-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, warning = FALSE, fig.retina = 3)
```


```{r}

packages = c('igraph','tidygraph','ggraph','hms','textplot','tidyverse','lubridate','ggwordcloud','DT','wordcloud',
             'widyr','tidytext')

for(p in packages){
if(!require(p, character.only = T)){
  install.packages(p)
  }
  library(p, character.only = T)
}


```


Step 1 - Create folder list
Step 2 - Define function to read all files from a folder into a data frame

```{r}

news20 <- "data/20news"

read_folder <- function(infolder) {
  tibble(file = dir(infolder,
                    full.names = TRUE)) %>%
    mutate(text = map(file,
                      read_lines)) %>%
    transmute(id = basename(file),
              text) %>%
    unnest(text)
}

```

Step 3 - Reading in all messages from the news20 folder into a data file in RDS folder. Remember to delete the original raw files before committing them to github!

```{r}

raw_text <- tibble(folder = 
                     dir(news20,
                         full.names = TRUE)) %>%
  mutate(folder_out = map(folder,
                          read_folder)) %>%
  unnest(cols = c(folder_out)) %>%
  transmute(newsgroup = basename(folder),
            id, text)

write_rds(raw_text, "data/rds/news20.rds")

```

Initial EDA

```{r}

raw_text %>%
  group_by(newsgroup) %>%
  summarise(messages = n_distinct(id)) %>%
  ggplot(aes(messages, newsgroup)) +
  geom_col(fill = 'lightblue') +
  labs(y = NULL)

```
Cleaning Text Data

Refer to [https://stringr.tidyverse.org/articles/regular-expressions.html](https://stringr.tidyverse.org/articles/regular-expressions.html) for regex reference

Step 1  - Remove headers and email signatures


```{r}

cleaned_text <- raw_text %>%
  group_by(newsgroup, id) %>%
  filter(cumsum(text == '') > 0,
         cumsum(str_detect(
           text, "^--")) == 0) %>%
  ungroup()

```

Step 2 - Remove lines with nested txt representing quotes from other users

```{r}

cleaned_text <- cleaned_text %>%
  filter(str_detect(text, "^[^>]+[A-Za-z\\d]")
         | text == "",
         !str_detect(text,
                     "writes(:|\\.\\.\\.)$"),
         !str_detect(text,
                     "^In article <")
         )

```

Step 3 - Unnest to split into tokens, and stop_words to remove stop words.

```{r}

usenet_words <- cleaned_text %>%
  unnest_tokens(word, text) %>%
  filter(str_detect(word, "[a-z']$"),
         !word %in% stop_words$word)

```

Get word counts

```{r}

usenet_words %>%
  count(word, sort = TRUE)

```

Create new tibble to indicate wordcount of each word

```{r}

words_by_newsgroup <- usenet_words %>%
  count(newsgroup, word, sort = TRUE) %>%
  ungroup()

```

Use worldcloud package to create wordcloud

```{r}

set.seed(230)

wordcloud(words_by_newsgroup$word,
          words_by_newsgroup$n,
          max.words = 300,
          random.order=TRUE,
          random.color = FALSE,
          colors=brewer.pal(8, "Dark2"),
          scale=c(1.5,0.5)
          )

```

Use ggwordcloud package to create wordcloud

```{r}

set.seed(1234)

words_by_newsgroup %>%
  filter(n > 0) %>%
  ggplot(aes(label = word,
           size = n)) +
  geom_text_wordcloud() +
  theme_minimal() +
  facet_wrap(~newsgroup)


```



```{r}

tf_idf <- words_by_newsgroup %>% 
  bind_tf_idf(word, newsgroup, n) %>% 
  arrange(desc(tf_idf))

```



```{r}

datatable(tf_idf)

```



```{r}

DT::datatable(tf_idf, filter = 'top') %>% 
  formatRound(columns = c('tf', 'idf','tf_idf'),
              digits = 3) %>% 
  formatStyle(0,
              target = 'row',
              lineHeight = '25%')

```

Visualize the TF-IDF

```{r}

tf_idf %>% 
  filter(str_detect(newsgroup, '^sci\\.')) %>% 
  group_by(newsgroup) %>% 
  slice_max(tf_idf,
            n=12) %>% 
  ungroup() %>% 
  mutate(word = reorder(word,
                        tf_idf)) %>% 
  ggplot(aes(tf_idf,
             word,
             fill = newsgroup)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~newsgroup,
             scales = 'free') +
  labs(x = 'TF_IDF', y = NULL)

```

Compute TF_IDF within newsgroups

```{r}

tf_idf <- words_by_newsgroup %>% 
  bind_tf_idf(word, newsgroup, n) %>% 
  arrange(desc(tf_idf))

```

Counting and Correlating pairs of words with the widyr package - find newsgroups that are close to each other based on the terms they commonly use.

```{r}

newsgroup_cors <- words_by_newsgroup %>% 
  pairwise_cor(newsgroup, word, n,
               sort = TRUE)

```

Visualizing Correlation as Network

```{r}

set.seed(2017)

newsgroup_cors %>% 
  filter(correlation > 0.025) %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = 'fr') +
  geom_edge_link(aes(alpha = correlation,
                     width = correlation)) +
  geom_node_point(size = 6,
                  color = 'lightblue') +
  geom_node_text(aes(label = name,
                     color = 'red',
                     repel = TRUE)) +
  theme_void()

```

Bigram

```{r}

bigrams <- cleaned_text %>% 
  unnest_tokens(bigram, text, token = 'ngrams', n=2)

```

Counting Bigram

```{r}

bigrams_count <- bigrams %>% 
  filter(bigram != 'NA') %>% 
  count(bigram, sort = TRUE)

```

Cleaning Bigram

```{r}

bigrams_separated <- bigrams %>% 
  filter(bigram != 'NA') %>% 
  separate(bigram, c('word1','word2'),
           sep = ' ')

bigrams_filtered <- bigrams_separated %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word2 %in% stop_words$word)

```

Do another bigram count

```{r}

bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

```


Create Network graph from bigram data frame

```{r}

bigram_graph <- bigram_counts %>% 
  filter(n > 3) %>% 
  graph_from_data_frame()

bigram_graph

```

Visualizing network of bigrams with ggraph


```{r}

set.seed(1234)

ggraph(bigram_graph, layout = 'fr') +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name,
                     vjust = 1,
                     hjust = 1))


```


Improving the graph

```{r}

set.seed(1234)

a <- grid::arrow(type = 'closed',
                 length = unit(.15, 'inches'))

ggraph(bigram_graph, layout = 'fr') +
  geom_edge_link(aes(edge_alpha = n),
                 show.legend = FALSE,
                 arrow = a,
                 end_cap = circle(.07, 'inches')) +
  geom_node_point(color = 'lightblue', size = 5) +
  geom_node_text(aes(label = name,
                     vjust = 1,
                     hjust = 1)) +
  theme_void()

```




```{r}



```




```{r}



```


















































