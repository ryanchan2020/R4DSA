---
title: "VAST Challenge - Mini-Challenge 3"
description: |
  Mini-Challenge 3
author:
  - name: Ryan Chan
    url: https://www.linkedin.com/in/ryan-chan-a7021b5/
date: 07-12-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, warning = FALSE, fig.retina = 3)
```


```{r}

packages = c('igraph','tidygraph','ggraph','hms','textplot','tidyverse','lubridate','ggwordcloud','DT','wordcloud',
             'widyr','tidytext','dplyr','clock','visNetwork','hms','qdapDictionaries', 'corpus','syuzhet')

for(p in packages){
if(!require(p, character.only = T)){
  install.packages(p)
  }
  library(p, character.only = T)
}


```



```{r}

mctext_files <- list.files(path = "data", pattern = '.csv$', full.names = TRUE) %>% 
  map(read_csv)

raw_data <- data.table::rbindlist(mctext_files, use.names = TRUE, idcol = "source")

write_rds(raw_data, "data/rds/raw_data.rds")

glimpse(raw_data)

```



```{r}


raw_data$timestamp <- paste(substring(raw_data$`date(yyyyMMddHHmmss)`,first = 9, last = 10),
                           substring(raw_data$`date(yyyyMMddHHmmss)`,first = 11, last = 12),sep=":")

raw_data$date <- paste(substring(raw_data$`date(yyyyMMddHHmmss)`, first = 1, last = 4),
                       substring(raw_data$`date(yyyyMMddHHmmss)`, first = 5, last = 6),
                       substring(raw_data$`date(yyyyMMddHHmmss)`, first = 7, last = 8),sep = "-")

raw_data$date <- parse_date(raw_data$date, format = "%Y-%m-%d")

raw_data$timestamp <- parse_time(raw_data$timestamp, format = "%AT")

raw_data$datetime <- paste(raw_data$date, raw_data$timestamp, sep = " ")
raw_data$datetime <- parse_date_time(raw_data$datetime, "%Y-%m-%d %H:%M:%S")
raw_data$time_block = cut(raw_data$datetime, breaks = "15 min")

glimpse(raw_data)

```



```{r}

raw_data$hashtags <- str_extract_all(raw_data$message,"(?<=#)\\w+\\b")
raw_data$hashtags[lengths(raw_data$hashtags) == 0] <- NA_character_
raw_data$retweet_source <- str_extract_all(raw_data$message,"(?<=RT @)\\S+\\b")
raw_data$retweet_source[lengths(raw_data$retweet_source) == 0] <- NA_character_
raw_data$cleaned_message <- str_replace_all(raw_data$message,"RT @\\S+\\s*\\b","")
raw_data$cleaned_message <- str_replace_all(raw_data$cleaned_message,"#\\w+\\s*\\b","")
raw_data$mentions <- if (str_extract_all(raw_data$cleaned_message,"(?<=@)\\S+\\b") %in% raw_data$author) {str_extract_all(raw_data$cleaned_message,"(?<=@)\\S+\\b")} else if (str_extract_all(raw_data$cleaned_message,"(?<=@)\\w+\\b") %in% raw_data$author) {str_extract_all(raw_data$cleaned_message,"(?<=@)\\w+\\b")}
raw_data$mentions[lengths(raw_data$mentions) == 0] <- NA_character_
raw_data$cleaned_message <- str_replace_all(raw_data$cleaned_message,"@\\S+\\s*\\b","")

```



```{r}

mb_words <- raw_data %>%
  filter(type == "mbdata") %>% 
  unnest_tokens(word, cleaned_message, drop = FALSE) %>%
  filter(str_detect(word, "[a-z']$"),
         !word %in% stop_words$word)

mb_words <- select(mb_words, -c(source, type, `date(yyyyMMddHHmmss)`, date, timestamp, message))

```

#############################################
Messages by Author
#############################################

```{r}

mb_messages_by_author <- raw_data %>% 
  filter(type == "mbdata") %>% 
  count(author, cleaned_message)

```



```{r}

mb_messages_by_author_aggregated <- mb_messages_by_author %>% 
  group_by(author) %>% 
  summarize(unique_count = n(), total_count = sum(n), junk_check = total_count/unique_count)

```


#############################################
Words by Timeblock
#############################################


```{r}

mb_words_by_timeblock <- mb_words %>% 
  count(time_block, word, sort=TRUE)

```



```{r}

mb_words_by_timeblock_tfidf <- mb_words_by_timeblock %>% 
  bind_tf_idf(word, time_block, n) %>%
  arrange(desc(tf_idf))

```

#############################################
Words by Author
#############################################

```{r}

mb_words_by_author <- mb_words %>%
count(author, word, sort = TRUE) %>%
ungroup()

```



```{r}

mb_words_by_author$in_dictionary <- if_else (mb_words_by_author$word %in% GradyAugmented,0,1)
mb_words_by_author$sentiment <- get_sentiment(mb_words_by_author$word, method = "syuzhet")
mb_words_by_author$total_in_dictionary <- mb_words_by_author$in_dictionary*mb_words_by_author$n
mb_words_by_author$total_sentiment <- mb_words_by_author$sentiment*mb_words_by_author$n

```



```{r}

mb_words_by_author_tfidf <- mb_words_by_author %>% 
  bind_tf_idf(word, author, n) %>%
  arrange(desc(tf_idf))

```



```{r}

mb_words_by_author_nested <- mb_words_by_author %>% 
  group_by(author) %>% 
  group_nest()

```



```{r}

set.seed(1234)
wordcloud(mb_words_by_author$word, mb_words_by_author$n, max.words = 300)

```



```{r}

mb_words_by_author_agg_sentiment <- mb_words_by_author %>% 
  group_by(author) %>% 
  summarise(grandtotal_sentiment = sum(total_sentiment)) %>% 
  arrange(desc(grandtotal_sentiment))

```




```{r}

mb_words_by_author_NotInDict <- mb_words_by_author %>%
  filter(total_in_dictionary > 0) %>% 
  group_by(author) %>% 
  summarise(sum(total_in_dictionary), data = list(word))

```



```{r}



```




```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```



```{r}



```